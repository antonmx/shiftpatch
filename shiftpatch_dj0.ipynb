{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Header</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Imports</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'inShape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshiftpatch_module\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msg\u001b[39;00m\n",
      "File \u001b[0;32m~/usr/src/shiftpatch/shiftpatch_module.py:281\u001b[0m\n\u001b[1;32m    278\u001b[0m         idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicies[index]\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask[idx[\u001b[38;5;241m0\u001b[39m]:idx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mDCfg\u001b[38;5;241m.\u001b[39minShape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], idx[\u001b[38;5;241m1\u001b[39m]:idx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39mDCfg\u001b[38;5;241m.\u001b[39minShape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m--> 281\u001b[0m samplingMask \u001b[38;5;241m=\u001b[39m \u001b[43mSamplingMask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mShiftedPair\u001b[39;00m :\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhdfData\u001b[39m(inputString):\n",
      "File \u001b[0;32m~/usr/src/shiftpatch/shiftpatch_module.py:268\u001b[0m, in \u001b[0;36mSamplingMask.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;241m=\u001b[39m loadImage(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampling_mask.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 268\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[43mDCfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minShape\u001b[49m)\n\u001b[1;32m    269\u001b[0m     imask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconvolve(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask, kernel, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicies \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margwhere( np\u001b[38;5;241m.\u001b[39mlogical_and(imask \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.9\u001b[39m, imask \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m) )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'inShape'"
     ]
    }
   ],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import shiftpatch_module as sg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Redefine</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.plt.rcParams['figure.dpi']=223\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Configs</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.set_seed(7)\n",
    "\n",
    "sg.TCfg = sg.TCfgClass(\n",
    "     exec = 0\n",
    "    ,nofEpochs = None\n",
    "    ,latentDim = 64\n",
    "    ,batchSize = 2**8\n",
    "    ,batchSplit = 1\n",
    "    ,labelSmoothFac = 0.1 # For Fake labels (or set to 0.0 for no smoothing).\n",
    "    ,learningRateD = 1e-4\n",
    "    ,learningRateG = 1e-4\n",
    ")\n",
    "\n",
    "sg.DCfg = sg.DCfgClass()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Raw Read</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.samplingMask = sg.SamplingMask()\n",
    "#trainSet = sg.createTrainSet()\n",
    "testSet = sg.createTestSet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Show</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.refImages, sg.refNoises = sg.createReferences(testSet, 1)\n",
    "sg.showMe(testSet, 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "source": [
    "## <font style=\"color:lightblue\">Models</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Generator</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Generator(sg.GeneratorTemplate):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__(0)\n",
    "        self.amplitude = 4\n",
    "\n",
    "        self.noise2latent = self.createLatent()\n",
    "\n",
    "        self.encoders =  nn.ModuleList([\n",
    "            self.encblock( (4+self.latentChannels) /self.baseChannels,\n",
    "                               1, 3, norm=False),\n",
    "            self.encblock( 1,  1, 3, dopadding=True),\n",
    "            self.encblock( 1,  2, 3, stride=2),\n",
    "            self.encblock( 2,  2, 3, dopadding=True),\n",
    "            self.encblock( 2,  4, 3, stride=2),\n",
    "            self.encblock( 4,  4, 3, dopadding=True),\n",
    "            self.encblock( 4,  8, 3, stride=2),\n",
    "            self.encblock( 8,  8, 3, dopadding=True),\n",
    "            self.encblock( 8, 16, 3, stride=2),\n",
    "            self.encblock(16, 16, 3, dopadding=True),\n",
    "            ])\n",
    "\n",
    "        self.fcLink = self.createFClink()\n",
    "\n",
    "        self.decoders = nn.ModuleList([\n",
    "            self.decblock(32, 16, 3, dopadding=True),\n",
    "            self.decblock(32,  8, 4, stride=2),\n",
    "            self.decblock(16,  8, 3, dopadding=True),\n",
    "            self.decblock(16,  4, 4, stride=2),\n",
    "            self.decblock( 8,  4, 3, dopadding=True),\n",
    "            self.decblock( 8,  2, 4, stride=2),\n",
    "            self.decblock( 4,  2, 3, dopadding=True),\n",
    "            self.decblock( 4,  1, 4, stride=2),\n",
    "            self.decblock( 2,  1, 3, dopadding=True),\n",
    "            self.decblock( 2,  1, 3, norm=False),\n",
    "            ])\n",
    "\n",
    "        self.lastTouch = self.createLastTouch()\n",
    "\n",
    "        #sg.load_model(self, model_path=\"saves/gap16/noBNreNorm4/model_gen.pt\" )\n",
    "\n",
    "\n",
    "\n",
    "sg.generator = Generator().to(sg.TCfg.device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Discriminator</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Discriminator(sg.DiscriminatorTemplate):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.body =  nn.Sequential(\n",
    "            self.encblock( 1/self.baseChannels,\n",
    "                               1, 3, norm=False),\n",
    "            self.encblock( 1,  1, 3, dopadding=True),\n",
    "            self.encblock( 1,  2, 3, stride=2),\n",
    "            self.encblock( 2,  2, 3, dopadding=True),\n",
    "            self.encblock( 2,  4, 3, stride=2),\n",
    "            self.encblock( 4,  4, 3, dopadding=True),\n",
    "            self.encblock( 4,  8, 3, stride=2),\n",
    "            self.encblock( 8,  8, 3, dopadding=True),\n",
    "            self.encblock( 8, 16, 3, stride=2),\n",
    "            self.encblock(16, 16, 3, dopadding=True),\n",
    "            )\n",
    "        self.head = self.createHead()\n",
    "        #sg.load_model(self, model_path=\"/mnt/bctpro.data/anton/sinogap/saves/gap16/noBNreNorm_pureAdv/model_dis.pt\" )\n",
    "\n",
    "\n",
    "sg.discriminator = Discriminator()\n",
    "sg.discriminator = sg.discriminator.to(sg.TCfg.device)\n",
    "model_summary = summary(sg.discriminator, input_data=sg.refImages[0,...] ).__str__()\n",
    "print(model_summary)\n",
    "#sg.writer.add_graph(sg.discriminator, refImages)\n",
    "\n",
    "sg.optimizer_D = sg.createOptimizer(sg.discriminator, sg.TCfg.learningRateD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Restore checkpoint</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sg.scheduler_G = None # torch.optim.lr_scheduler.StepLR(sg.optimizer_G, 1, gamma=1.001)\n",
    "sg.scheduler_D = None\n",
    "#sg.scheduler_D = torch.optim.lr_scheduler.StepLR(sg.optimizer_D, 1, gamma=0.999)\n",
    "savedCheckPoint = f\"checkPoint_{sg.TCfg.exec}\"\n",
    "sg.epoch, sg.imer, sg.minGEpoch, sg.minGdLoss, sg.startFrom, sg.resAcc = \\\n",
    "    sg.restoreCheckpoint(savedCheckPoint+\".pth\")\n",
    "#sg.epoch, sg.imer, sg.minGEpoch, sg.minGdLoss, sg.startFrom = 0, 0, 0, 1, 0\n",
    "sg.writer = sg.createWriter(sg.TCfg.logDir, True)\n",
    "#sg.writer.add_graph(sg.generator, ((sg.refImages, sg.refNoises),) )\n",
    "#sg.writer.add_graph(sg.discriminator, refImages)\n",
    "sg.initialTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"amplitude: \", sg.generator.amplitude.item(), 2 * torch.sigmoid(sg.generator.amplitude).item() )\n",
    "#print(sg.epoch, sg.imer, sg.minGEpoch, sg.minGdLoss, sg.startFrom)\n",
    "#lastLR = sg.scheduler_D.get_last_lr()[0]\n",
    "#print(f\"Initial LR : {lastLR:.6e}  {lastLR/sg.TCfg.learningRateD:.3f}\")\n",
    "#print(f\"{sg.normRec.item():e}, {sg.normMSE.item():e}, {sg.normL1L.item():e}\")\n",
    "#print(f\"{sg.normTestRec.item():e}, {sg.normTestMSE.item():e}, {sg.normTestL1L.item():e}\")\n",
    "#sg.freeGPUmem()\n",
    "#sg.load_model(sg.generator, model_path=\"saves/gap16/noBNreNorm4/model_gen.pt\" )\n",
    "#sg.initialTest()\n",
    "#lastLR = sg.scheduler_G.get_last_lr()[0]\n",
    "#print(f\"Initial LR : {lastLR:.6e}  {lastLR/sg.TCfg.learningRateG:.3f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Execute</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "sg.noAdv = False\n",
    "sg.dataLoader = sg.createDataLoader(trainSet, num_workers=16)\n",
    "sg.testLoader = sg.createDataLoader(testSet , num_workers=16)\n",
    "#sg.scheduler_G = None\n",
    "#sg.scheduler_D = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sg.normRec, sg.normMSE, sg.normL1L, _ , _ = sg.summarizeSet(sg.dataLoader)\n",
    "#sg.normTestRec, sg.normTestMSE, sg.normTestL1L, _ , _ = sg.summarizeSet(sg.testLoader)\n",
    "sg.normRec, sg.normMSE, sg.normL1L = 4.031e-03, 6.579e-03, 2.047e-02\n",
    "sg.normTestRec, sg.normTestMSE, sg.normTestL1L = 4.868e-03, 1.382e-03, 1.369e-02\n",
    "if sg.epoch == 0 :\n",
    "    if sg.normRec == 1:\n",
    "        sg.normRec, sg.normMSE, sg.normL1L, _ , _ = sg.summarizeSet(sg.dataLoader)\n",
    "        sg.normTestRec, sg.normTestMSE, sg.normTestL1L, _ , _ = sg.summarizeSet(sg.testLoader)\n",
    "    #sg.minGdLoss = sg.normTestRec\n",
    "    #with torch.no_grad(): sg.generator.amplitude[()] = -math.log(1+2/sg.normMSE)\n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#def my_afterEachEpoch(epoch) :\n",
    "#    if sg.minGEpoch < 600 :\n",
    "#        return\n",
    "#    if not sg.dataLoader is None :\n",
    "#        del sg.dataLoader\n",
    "#        sg.freeGPUmem()\n",
    "#    if sg.TCfg.batchSize < 131072 :\n",
    "#    sg.TCfg.batchSize += round( 0.01 * sg.TCfg.batchSize )\n",
    "#    sg.dataLoader = sg.createTrainLoader(trainSet, num_workers=24)\n",
    "#    print(\"Batch size: \",sg.TCfg.batchSize)\n",
    "#sg.afterEachEpoch = my_afterEachEpoch\n",
    "\n",
    "\n",
    "#lastLR = sg.scheduler_G.get_last_lr()[0]\n",
    "#print(f\"Initial LR : {lastLR:.6e}  {lastLR/sg.TCfg.learningRateG:.3f}\")\n",
    "#def my_beforeReport() :\n",
    "#    lastLR = sg.scheduler_G.get_last_lr()[0]\n",
    "#    print(f\"LR : {lastLR:.6e} {lastLR/sg.TCfg.learningRateG:.3f}\")\n",
    "#    if sg.scheduler_G.get_last_lr()[0]  >  5 * sg.TCfg.learningRateG :\n",
    "#        return\n",
    "#    if sg.scheduler_G is not None :\n",
    "#        sg.scheduler_G.step()\n",
    "#    if sg.scheduler_D is not None :\n",
    "#        sg.scheduler_D.step()\n",
    "#    return\n",
    "#sg.beforeReport = my_beforeReport\n",
    "\n",
    "sg.lossAdvCoef = 1.0\n",
    "sg.lossDifCoef = 40\n",
    "\n",
    "def my_beforeReport() :\n",
    "    sg.lossDifCoef = min (sg.lossDifCoef * 1.001, 100.0)\n",
    "    print(f\"lossDifCoef: {sg.lossDifCoef}\")\n",
    "    with open(f\"message_{sg.TCfg.exec}.txt\", 'a') as file:\n",
    "        file.write(f\"lossDifCoef: {sg.lossDifCoef}\\n\")\n",
    "sg.beforeReport = my_beforeReport\n",
    "\n",
    "try :\n",
    "    sg.train(savedCheckPoint)\n",
    "except :\n",
    "    del sg.dataLoader\n",
    "    del sg.testLoader\n",
    "    sg.freeGPUmem()\n",
    "    1/10 # to release Jupyuter memory in the next step\n",
    "    sg.epoch -= 1\n",
    "    raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Post</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sg.generator.amplitude.item(), 2 * torch.sigmoid(sg.generator.amplitude).item() )\n",
    "sg.initialTest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.testMe(trainSet, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Save results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.saveModels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
