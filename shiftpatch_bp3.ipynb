{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Header</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Imports</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import itertools\n",
    "import random\n",
    "import torchvision\n",
    "import ssim\n",
    "\n",
    "import shiftpatch_module as sg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Redefine</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.plt.rcParams['figure.dpi']=223\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Configs</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.set_seed(7)\n",
    "\n",
    "sg.TCfg = sg.TCfgClass(\n",
    "     exec = 3\n",
    "    ,nofEpochs = None\n",
    "    ,latentDim = 64\n",
    "    ,batchSize = 2**8\n",
    "    ,batchSplit = 2**0\n",
    "    ,loaderWorkers = 16\n",
    "    ,labelSmoothFac = 0.1 # For Fake labels (or set to 0.0 for no smoothing).\n",
    "    ,learningRateD = 1e-4\n",
    "    ,learningRateG = 1e-4\n",
    ")\n",
    "\n",
    "sg.DCfg = sg.DCfgClass()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Raw Read</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.samplingMask = sg.SamplingMask()\n",
    "sg.samplingVari = sg.SamplingVariations()\n",
    "sg.trainSet = sg.createTrainSet()\n",
    "sg.testSet = sg.createTestSet()\n",
    "sg.testLoader = sg.createDataLoader(sg.createSubSet(sg.testSet),\n",
    "                                    num_workers=sg.TCfg.loaderWorkers)\n",
    "sg.refImages, sg.refNoises = sg.createReferences(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Show</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sg.showMe(sg.testSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "source": [
    "## <font style=\"color:lightblue\">Models</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.batchNormOpt = { #\"track_running_stats\" : False,\n",
    "                    #\"momentum\" : 0.5,\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Generator</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_interim = False\n",
    "class Generator(sg.GeneratorTemplate):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__(latentChannels=1, inputChannels=2)\n",
    "        self.amplitude = 1\n",
    "        self.baseChannels = 16\n",
    "\n",
    "        self.noise2latent = self.createLatent()\n",
    "\n",
    "        self.encoders =  nn.ModuleList([\n",
    "            self.encblock( (self.inputChannels+abs(self.latentChannels)) /self.baseChannels,\n",
    "                               1, 3, norm=False,),\n",
    "            self.encblock( 1,  1, 3, norm=True, dopadding=True),\n",
    "            self.encblock( 1,  2, 3, norm=True, stride=2),\n",
    "            self.encblock( 2,  2, 3, norm=True, dopadding=True),\n",
    "            self.encblock( 2,  4, 3, norm=True, stride=2),\n",
    "            self.encblock( 4,  4, 3, norm=True, dopadding=True),\n",
    "            self.encblock( 4,  8, 3, norm=True, stride=2),\n",
    "            self.encblock( 8,  8, 3, norm=True, dopadding=True),\n",
    "            self.encblock( 8, 16, 3, norm=True, stride=2),\n",
    "            self.encblock(16, 16, 3, norm=True, dopadding=True),\n",
    "            ])\n",
    "\n",
    "        self.fcLink = self.createFClink()\n",
    "\n",
    "        self.decoders = nn.ModuleList([\n",
    "            self.decblock(32, 16, 3, norm=True, dopadding=True),\n",
    "            self.decblock(32,  8, 4, norm=True, stride=2),\n",
    "            self.decblock(16,  8, 3, norm=True, dopadding=True),\n",
    "            self.decblock(16,  4, 4, norm=True, stride=2),\n",
    "            self.decblock( 8,  4, 3, norm=True, dopadding=True),\n",
    "            self.decblock( 8,  2, 4, norm=True, stride=2),\n",
    "            self.decblock( 4,  2, 3, norm=True, dopadding=True),\n",
    "            self.decblock( 4,  1, 4, norm=True, stride=2),\n",
    "            self.decblock( 2,  1, 3, norm=True, dopadding=True),\n",
    "            self.decblock( 2,  1, 3, norm=False),\n",
    "            ])\n",
    "\n",
    "        self.lastTouch = self.createLastTouch()\n",
    "\n",
    "        #sg.load_model(self, model_path=\"model_2_gen.pt\" )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sg.generator = Generator().to(sg.TCfg.device)\n",
    "sg.optimizer_G = sg.createOptimizer(sg.generator, sg.TCfg.learningRateG)\n",
    "model_summary = summary(sg.generator, input_data=[ [sg.refImages[[0,1],0:4,...], sg.refNoises[[0,1],...]] ] ).__str__()\n",
    "#print(model_summary)\n",
    "\n",
    "#checkPoint = torch.load(\"saves/mssim_mili/checkPoint.pth\", map_location=sg.TCfg.device, weights_only=False)\n",
    "#sg.optimizer_G.load_state_dict(checkPoint['optimizerGen'])\n",
    "#sg.optimizer_G.step()\n",
    "#torch.optim.lr_scheduler.LambdaLR(sg.optimizer_G, lambda epoch: 1).step()\n",
    "\n",
    "\n",
    "#_ = sg.testMe(sg.refImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Discriminator</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.discriminatePair = True\n",
    "class DiscriminatorIMG(sg.DiscriminatorTemplate):\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorIMG, self).__init__()\n",
    "        self.baseChannels = 16\n",
    "        self.body =  nn.Sequential(\n",
    "            self.encblock( 2/self.baseChannels,\n",
    "                               1, 3, norm=False,),\n",
    "            self.encblock( 1,  1, 3, norm=False, dopadding=True),\n",
    "            self.encblock( 1,  2, 3, norm=False, stride=2),\n",
    "            self.encblock( 2,  2, 3, norm=False, dopadding=True),\n",
    "            self.encblock( 2,  4, 3, norm=False, stride=2),\n",
    "            self.encblock( 4,  4, 3, norm=False, dopadding=True),\n",
    "            self.encblock( 4,  8, 3, norm=False, stride=2),\n",
    "            self.encblock( 8,  8, 3, norm=False, dopadding=True),\n",
    "            self.encblock( 8, 16, 3, norm=False, stride=2),\n",
    "            self.encblock(16, 16, 3, norm=False, dopadding=True),\n",
    "            )\n",
    "        self.head = self.createHead()\n",
    "        #sg.load_model(self, model_path=\"saves/msssim1_noFFT/model_dis.pt\" )\n",
    "\n",
    "\n",
    "fftNorm = torch.tensor(sg.loadImage(\"NormFFT.tif\"), device=sg.TCfg.device)[None,None,...]\n",
    "\n",
    "class DiscriminatorFFT(sg.DiscriminatorTemplate):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorFFT, self).__init__()\n",
    "        self.baseChannels = 16\n",
    "        self.chIn = 2\n",
    "        self.body =  nn.Sequential(\n",
    "            self.encblock( self.chIn/self.baseChannels,\n",
    "                               1, 3, norm=False,),\n",
    "            self.encblock( 1,  1, 3, norm=False, dopadding=True),\n",
    "            self.encblock( 1,  2, 3, norm=False, stride=2),\n",
    "            self.encblock( 2,  2, 3, norm=False, dopadding=True),\n",
    "            self.encblock( 2,  4, 3, norm=False, stride=2),\n",
    "            self.encblock( 4,  4, 3, norm=False, dopadding=True),\n",
    "            self.encblock( 4,  8, 3, norm=False, stride=2),\n",
    "            self.encblock( 8,  8, 3, norm=False, dopadding=True),\n",
    "            self.encblock( 8, 16, 3, norm=False, stride=2),\n",
    "            self.encblock(16, 16, 3, norm=False, dopadding=True),\n",
    "            )\n",
    "        self.head = self.createHead()\n",
    "        #sg.load_model(self, model_path=\"/data/anton/shiftpatch/model_dis_fft.pt\" )\n",
    "\n",
    "    def forward(self, images):\n",
    "        if images.dim() == 3:\n",
    "            images = images.unsqueeze(1)\n",
    "        fftIO = images[:,[0],...] + 1j * images[:,[1],...]\n",
    "        fftIO = torch.fft.fft2(fftIO, norm=\"forward\") / fftNorm\n",
    "        modelIn = torch.concat( (fftIO.real, fftIO.imag), dim=1 )\n",
    "        convRes = self.body(modelIn)\n",
    "        res = self.head(convRes)\n",
    "        return res\n",
    "\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.discIMG = DiscriminatorIMG()\n",
    "        self.discFFT = DiscriminatorFFT()\n",
    "        self.IMG_FFT = 0.5\n",
    "        #sg.load_model(self, model_path=\"model_3_dis.pt\" )\n",
    "    def forward(self, images):\n",
    "        if images.dim() == 3:\n",
    "            images = images.unsqueeze(1)\n",
    "        resIMG = self.discIMG(images)\n",
    "        #resFFT = self.discFFT(images)\n",
    "        res = resIMG #* self.IMG_FFT  + (1-self.IMG_FFT) * resFFT\n",
    "        #print(resIMG, resFFT)\n",
    "        return res\n",
    "\n",
    "\n",
    "sg.discriminator = Discriminator()\n",
    "sg.discriminator = sg.discriminator.to(sg.TCfg.device)\n",
    "model_summary = summary(sg.discriminator, input_data=sg.refImages[[0],0:2,...] ).__str__()\n",
    "#print(model_summary)\n",
    "#sg.writer.add_graph(sg.discriminator, refImages)\n",
    "\n",
    "sg.optimizer_D = sg.createOptimizer(sg.discriminator, sg.TCfg.learningRateD)\n",
    "#sg.optimizer_D.step()\n",
    "#torch.optim.lr_scheduler.LambdaLR(sg.optimizer_D, lambda epoch: 1).step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.noAdv = False\n",
    "sg.MSSSIM = ssim.MS_SSIM(data_range=2.0, size_average=False, channel=1, win_size=1)\n",
    "#sg.normTestRec, sg.normTestMSE, sg.normTestL1L = sg.summarizeSet(sg.testLoader)[0:3]\n",
    "#print(f\"{sg.normTestRec:.3e}, {sg.normTestMSE:.3e}, {sg.normTestL1L:.3e}\")\n",
    "#sg.normRec, sg.normMSE, sg.normL1L = sg.summarizeSet(\n",
    "#                                            sg.createDataLoader(\n",
    "#                                                sg.createSubSet(sg.trainSet),\n",
    "#                                                num_workers=sg.TCfg.loaderWorkers))[0:3]\n",
    "#print(f\"{sg.normRec:.3e}, {sg.normMSE:.3e}, {sg.normL1L:.3e}\")\n",
    "\n",
    "#sg.normTestRec, sg.normTestMSE, sg.normTestL1L =  3.185e-03, 3.845e-04, 6.890e-03 # 8.905e-05, 4.314e-04, 7.362e-03\n",
    "#sg.normRec, sg.normMSE, sg.normL1L = 1.443e-02, 2.267e-03, 1.797e-02 # 1.170e-04, 1.915e-03, 1.639e-02\n",
    "sg.normTestRec, sg.normTestMSE, sg.normTestL1L = 8.905e-05, 3.845e-04, 6.890e-03 # 4.314e-04, 7.362e-03\n",
    "sg.normRec, sg.normMSE, sg.normL1L = 1.170e-04, 2.267e-03, 1.797e-02 #1.915e-03, 1.639e-02\n",
    "\n",
    "\n",
    "# SSIM:   bs0 4.463e-02, 1.044e-02 # bsMean 4.503e-02, 1.025e-02 # bs- 4.448e-02, 1.028e-02 # mskMean 4.739e-02, 1.078e-02\n",
    "# MSSSIM: bs0 1.431e-02, 3.716e-03 # bsMean 1.443e-02, 3.185e-03 # bs- 1.354e-02, 3.096e-03\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Restore checkpoint</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.scheduler_G = torch.optim.lr_scheduler.StepLR(sg.optimizer_G, 1, gamma=1)\n",
    "sg.scheduler_D = torch.optim.lr_scheduler.StepLR(sg.optimizer_D, 1, gamma=1)\n",
    "savedCheckPoint = f\"checkPoint_{sg.TCfg.exec}\"\n",
    "sg.epoch, sg.imer, sg.minRecTest, sg.minRecTrain, sg.minTestEpoch, sg.startFrom, sg.resAcc = \\\n",
    "    sg.restoreCheckpoint(savedCheckPoint+\".pth\")\n",
    "\n",
    "sg.scheduler_G.gamma = 1-0.01\n",
    "sg.scheduler_D.gamma = 1-0.01\n",
    "#sg.optimizer_G.step()\n",
    "#torch.optim.lr_scheduler.LambdaLR(sg.optimizer_G, lambda epoch: 0.1).step()\n",
    "#sg.optimizer_D.step()\n",
    "#torch.optim.lr_scheduler.LambdaLR(sg.optimizer_D, lambda epoch: 0.1).step()\n",
    "#sg.startFrom = 0\n",
    "#sg.epoch, sg.imer, sg.minGEpoch, sg.minGdLoss, sg.startFrom = 0, 0, 0, 1, 0\n",
    "\n",
    "#sg.epoch = 0\n",
    "#sg.imer = 0\n",
    "#sg.optimizer_G.step()\n",
    "#torch.optim.lr_scheduler.LambdaLR(sg.optimizer_G, lambda epoch: 1).step()\n",
    "print(f\"Initial LR :{sg.scheduler_G.get_last_lr()[0]/sg.TCfg.learningRateG} {sg.epoch} {sg.imer}\")\n",
    "\n",
    "sg.writer = sg.createWriter(sg.TCfg.logDir, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "_ = sg.testMe(sg.refImages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Execute</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.freeGPUmem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "\n",
    "sg.noAdv = True\n",
    "sg.ADV_DIF = 0\n",
    "sg.SSIM_MSE = 1 - 1e-4\n",
    "#sg.discriminator.IMG_FFT = 0.5\n",
    "#sg.skipThreshold = 0.3\n",
    "\n",
    "def adjustScheduler(scheduler, iniLr, target) :\n",
    "    if scheduler is None :\n",
    "        return \"\"\n",
    "    gamma = scheduler.gamma\n",
    "    curLR = scheduler.get_last_lr()[0] / iniLr\n",
    "    if gamma < 1 and curLR > target \\\n",
    "    or gamma > 1 and curLR < target :\n",
    "        scheduler.step()\n",
    "    return f\"LR : {curLR:.2e}. \"\n",
    "\n",
    "\n",
    "def my_beforeReport(_) :\n",
    "    message = \"\"\n",
    "    message += \"G\" + adjustScheduler(sg.scheduler_G, sg.TCfg.learningRateG, 0.01)\n",
    "    message += \"D\" + adjustScheduler(sg.scheduler_D, sg.TCfg.learningRateD, 0.01)\n",
    "    #message += f\" ADV/DIF : {sg.ADV_DIF:.3e}.\"\n",
    "    #sg.ADV_DIF = max(1e-6, sg.ADV_DIF+1e-8)\n",
    "#    message += f\" Ampl : {sg.generator.amplitude:.3f}.\"\n",
    "#    sg.generator.amplitude = min(1, sg.generator.amplitude * (1+5e-3) )\n",
    "    with open(f\"message_{sg.TCfg.exec}.txt\", 'a') as file:\n",
    "        file.write(message + \"\\n\")\n",
    "    print(message)\n",
    "    return\n",
    "#sg.beforeReport = my_beforeReport\n",
    "\n",
    "#sg.TCfg.loaderWorkers = 0 # for debug single threaded\n",
    "try :\n",
    "    sg.train(savedCheckPoint)\n",
    "except :\n",
    "    #del sg.dataLoader\n",
    "    #del sg.testLoaderrelo\n",
    "    sg.freeGPUmem()\n",
    "    1/10 # to release Jupyuter memory in the next step\n",
    "    sg.epoch -= 1\n",
    "    raise\n",
    "\n",
    "# From pureSSIM\n",
    "# SSIM_MSE = 1 - 1e-5, LRs = 0.1\n",
    "# SSIM_MSE 1 - 1e-5 => 1-1e-4 (e3) => 1-1e-3 (e4) => 1-1e-4 (e8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:lightblue\">Post</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sg.generator.amplitude.item(), 2 * torch.sigmoid(sg.generator.amplitude).item() )\n",
    "sg.initialTest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.testMe(trainSet, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:lightblue\">Save results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.saveModels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
